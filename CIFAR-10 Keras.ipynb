{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_keras (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjSGcBT1y4D8",
        "outputId": "58f07502-e711-493e-c019-d7c3a80f9650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from keras import models,layers\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R3PnsOiqy4Ep",
        "outputId": "9fabc1ac-687f-4ec9-dd9d-6abc6ba8cce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# loading the dataset\n",
        "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gv5NWnEPy4FQ",
        "outputId": "83bbf220-3f04-421f-fc8c-66217adf65f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixQwYgs3y4F_",
        "colab": {}
      },
      "source": [
        "labels=['airplane', 'automobile','bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtn_1uyTy4GP",
        "outputId": "889d96fc-fff7-489c-db6b-06f63f59295c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#explore data\n",
        "print(ytrain[10])\n",
        "plt.imshow(xtrain[10])\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHXBJREFUeJztnW+MXOd13p9z7/yf3eWSIsXQtFA5\njorACRrZIAQXMQI3QQLVCCAbCAz7g6EPRhgUMRAD6QfBBWoX6AenqG34kwu6FqIUrv80tmGhMNq4\nQgAhXxRTjizLVho7rhyLokiK3P+z8/eefphRSrHvc3aWy52V/D4/gODufefee+ade+buvM8855i7\nQwiRH8VRByCEOBqU/EJkipJfiExR8guRKUp+ITJFyS9Epij5hcgUJb8QmaLkFyJTagfZ2cweBPBZ\nACWA/+zunwxP1qh5s9VMDwZfNDSyPfpyYlHy97WyLPmOwUEnVZXczuIDADM+6uR4e+1XBGNGnlph\nfD6qij/naMydx88ogrmPnlf0TdRozIr08x6PJnSf8XhMxxDEGF0J4XVA4o/mdzxOxz8Zj1FVVRTk\n/4vpdr/ea2YlgL8D8NsAXgTwHQAfdPcfsn26K13/lXO/kj5ecJEVk/QkBLug3e3SsWPHjtGxKkjI\nra2t5PbCeCCtRp2O9Xd6dKzdaNGxRoMncrObfj9v1vnx+n1+sff7Qz422KVjVqSvv6XuEt2n2eIx\njscjOjYc8hibzXZy+/VX1uk+V65co2Nljdy8AFjJX+vohjMapZ9b9LzW1taS21+5chWj4XCu5D/I\nn/0PAPixu//E3YcAvgzgoQMcTwixQA6S/GcB/Oym31+cbRNCvAE40Gf+eTCz8wDOA0Cj2Tjs0wkh\n5uQgd/5LAO656fc3z7a9Bne/4O7n3P1crXHo7zVCiDk5SPJ/B8B9ZvYWM2sA+ACAx+9MWEKIw+a2\nb8XuPjazjwD4n5hKfY+6+w/CfaoKg+F2cqxZ8lAqokiUweqqg0s5O730qj0A1Ov8o0m7k17pHUSr\n3jW+8Lp0jK98N4rgpan4KnCjSKsVK0t8JX13m69uF87nsd3mK99MMxmOeewIhjqd9Ko9AFgRyD5E\nLlta7tBdXnmFv2ajQAYsg3tppKqx1f5IearV0tdHJCn+f8eY+5EJ3P1bAL51kGMIIY4GfcNPiExR\n8guRKUp+ITJFyS9Epij5hciUBX/rxqkER7w7AIDxYJDc3mpxuaasuAzYbnOJbWVlhY5t7+wktw/H\nfbpPs8MltnadS2VloF4Ndrn8xkxGG+s36D7VhJtm6nU+j6NAVSqJqzIyuNRqfGww5HMcxV9N0kEG\nKhqawTdRx7tc6oukuQjmIoyOtx9Jj6E7vxCZouQXIlOU/EJkipJfiExR8guRKQtd7beiQJus0I/6\n6RV9ACiIySVe8eQrpWUtqGcXGFmMrKS3u3xFPzKyNOqBmSmoUba8ysuQ1cr0yvFLl16m+zSbXDUp\nAvOUBXOFMv3alHU+96Ngrna204YwAGgUXCWoE0UlugZWAsPVcMzjGAz5NRepJsykMyAqFwAsLy8n\nt1+L6lPegu78QmSKkl+ITFHyC5EpSn4hMkXJL0SmKPmFyJTFSn1WoF5L12Krgreh7kp6n93dtNEG\nAHb73AiytbVJxyzoG1aRenDjips9ul1eey6qM9gODEFlIBFOyPv58sm76T7RZbC1yaUtJ/UCAaBO\njD0j53M1CaTDk6dP0rEGuLxVsW5PwQU3GgYxTiJjD5eeoxZgTOqLOvZ0Oml5tiDtyZKPnfuRQoif\nK5T8QmSKkl+ITFHyC5EpSn4hMkXJL0SmHEjqM7MXAGwBmAAYu/u5PfYALO1uWlri9exatfQ+YX25\nqkfH6oGjazjiTioQF2HkBGy1uWMucjLu7PIWYDt9Lil1ltKOtCpo/7Wzzc/VXuEOwt4OrwsI4kpc\nXkm70QBgEEhbkezlzuej0SAt1gIpuBW1Iav4ax21j4skQhZjs8njYC2+orZgt3IndP5/4e6v3IHj\nCCEWiP7sFyJTDpr8DuAvzOxpMzt/JwISQiyGg/7Z/y53v2RmdwP4tpn9rbs/efMDZm8K5wGg2eKf\nYYQQi+VAd353vzT7/yqAbwB4IPGYC+5+zt3P1Rp8QUQIsVhuO/nNrGtmy6/+DOB3ADx3pwITQhwu\nB/mz/zSAb8yKaNYA/Fd3/x/RDu7AiLisAiUKfdIOq/CgTdOISzkD4s4DgHqTu/DKRrqN0xKR1wDA\nAsfZZBI86UA+jNpabaxvpeOYcFmxHxTHXF7mz+3EEpcBrUpLc2XkfAvqgfZ6/PXcCRxzq8fSc1VE\nhURJ7ADQDiTp3ja/Hq3Yv+MvqOGKYBrn5raT391/AuDXDh6CEOIokNQnRKYo+YXIFCW/EJmi5Bci\nU5T8QmTKQgt4Ak5dR4Mhl6I6zfSXg7odLstN6lwnifrP1UgvQQB4+Vrav9Qb8EKi3c4KHWvVeZHO\n8Yg77VpBAU+QYqIWyJvtOteNJoFkuhQ4Foe7ablsGDgZy0DCbLWD1zqQ+tiz7nR57P0Bf84rK1z6\n3Nnm/rZ2q0vHnBQTnQRaX0X6Ru4H3fmFyBQlvxCZouQXIlOU/EJkipJfiExZ6Gp/URRok1XbyZCv\nsJZlehWYbQeAdmC2qZGaaQAwChwTrGagT7gjZWttncfhXHVoFPyY3RUef2npl3R3wE0nd5/kBp1+\nsOI8nvBj1shcRSvp7SZXP2p03R4oSG1FABiP0zFubHDzTj+o71evp81dAFAGtSERrM7XiMmo9Mh8\nRK6PfRh+dOcXIlOU/EJkipJfiExR8guRKUp+ITJFyS9Epixc6ut00oaK9T43x4zHaZnEnYcfyYBR\nR6Nejxtq2DFbgXSIEZeoJkPeUszqfL/Tx95Ex/7PSy8lt59c5Qaj48eP07HNXS459na51DciEltU\nwZk/Y2BS8dEqGNslbc+iVlhRG7hqwu+XtUDqC9t8kQKW4zGXIyum6e3D76M7vxCZouQXIlOU/EJk\nipJfiExR8guRKUp+ITJlT6nPzB4F8LsArrr7r862nQDwFQD3AngBwPvdfW2vY7k7bU1kgTNrNExL\nHpubXAopV3iNNgscc5FWwhyJox6X7E6e4DJaWeO15+oTfszhZrolFwDsbqWlrS64tHXtpWt0bL3H\n5bwicOHVW2n3WxXUEpwQeRAAdgM3YKPgsi5rpdbt8pp6m8H8Nuq8lmBvh8e4scFbojHnYZ20hwOA\n8ZBfO/Myz53/TwE8eMu2RwA84e73AXhi9rsQ4g3Ensnv7k8CuHHL5ocAPDb7+TEA773DcQkhDpnb\n/cx/2t0vz35+GdOOvUKINxAHXvDzaSF++kHZzM6b2UUzuzga8M/oQojFcrvJf8XMzgDA7P+r7IHu\nfsHdz7n7uXqTL2AIIRbL7Sb/4wAenv38MIBv3plwhBCLYh6p70sA3g3gpJm9CODjAD4J4Ktm9mEA\nPwXw/oMGEkkvg15aJhmPubQyHPGPGIEyhMAgBpTp98pjK7wA5ihoT9UKAvE+l/pe/oef0bHV1TPJ\n7f1tXkh0Y2OTjm2PuPS5cppfPuMiPZHDoLVWLfjLsBGM9Te5I3RlJe1m7AXybD1oh1aSawAAmqSt\nHABUpI0aABRE5W4EDsgJKe4ZSea3smfyu/sHydBvzX0WIcTrDn3DT4hMUfILkSlKfiEyRckvRKYo\n+YXIlIUW8ASACZE8ojZnZT0tiRVl0HMvkKja5HgA0GoEMg+RgDwo0rm1w91cVcnPdazJXYm9XS5x\nrv0sXcCzVnHHXKvN57HT4mOrJ0/RsSvXryS3e1RhcsTdlpGCVQtez14vLQPWAjmv3eJuxe2tDR5H\nJAMGDr3hMH39DIJvxDYbaXehMd0wge78QmSKkl+ITFHyC5EpSn4hMkXJL0SmKPmFyJSFSn3uFcbD\ntEzlZSBRkLeoygNXnPH3td1AQjl1jLsLl5bTY5cupWUtAJjU+fOaRAUa21zqa7S5i/DG8z9Kbi+C\n4pinO7wo5dKJdAFMAJgEV0+D9GQMC7pMokZzXE7tLvH4t7bSxThrdT73ozF3Yk5GfMwm/Hosg+tx\nNEy/NuMJn6t6jTxn9eoTQuyFkl+ITFHyC5EpSn4hMkXJL0SmLHa1v6ow6afbSaHkK6X1YGWWUQXF\n+KoJX/ne2Q7aZJGV3nFU+C94XmPjS7M7QQ3Ck8e5oabVTCsSXpB5B+DBSnpZ5zEOBty0NBqmz+eT\noIZfVFzReRzDwOjUIopKLVh9j8xH40itqHj8BbjqU2MGr2A++rtkfsMilLfGJITIEiW/EJmi5Bci\nU5T8QmSKkl+ITFHyC5Ep87TrehTA7wK46u6/Otv2CQC/D+Da7GEfc/dv7Xk2dxgxmIwHXH5jUTaa\nPPx6OzBZ1HgbpKhYnCF9zNXVE3Sfa6/coGOd5cC8E8TRXeZGlhMklp112ksV4xGXyrY3r9Ox1dNc\nclwnMmAzqFtYD+rPVWMuYe3s8PjPvuksHWO8cu0aHWvUuOzcrPPXs9/ntf/M09f+JHjORVC3cF7m\nufP/KYAHE9s/4+73z/7tnfhCiNcVeya/uz8JgN++hBBvSA7ymf8jZvasmT1qZsfvWERCiIVwu8n/\nOQBvBXA/gMsAPsUeaGbnzeyimV0cj/hXO4UQi+W2kt/dr7j7xN0rAJ8H8EDw2Avufs7dz0WNEoQQ\ni+W2kt/Mztz06/sAPHdnwhFCLIp5pL4vAXg3gJNm9iKAjwN4t5ndj2nFsBcA/ME8JyvM0CAOvarg\nTionjq6KtP4CgHojkPMCxmPeMqrFWmgFDrGTp07SsQI8/kaLSzmTijvLamQe7zq+SvdZ2+Ey4Poa\ndzkuHVuhY8UkPY9LS8t0nwmpZQcAgQES3TqXPnfW0zX8mk3ehgxjfrJmya+rrY11Ojbs89eM1TWc\nOL+uSiKZ7qOE397J7+4fTGz+wj7OIYR4HaJv+AmRKUp+ITJFyS9Epij5hcgUJb8QmbLQb91YUaLe\nSrd/Csxe6Pd3kttHY16UcneXS3ZFweWaiu+G3V5akmmtcMnrzNlfoGODXe706vV5ccylFpepWq30\n9q3rm3SfoH4nLOjJtXE9LaMBwLCXljE3x3yfdlCotRa8Zr3t9PUBABv9tPx2/Dj/Rnqz4PO7vsZt\nLtdvrNGxTjc4H3ne/VFwMe5L1EujO78QmaLkFyJTlPxCZIqSX4hMUfILkSlKfiEyZbEG+6JA2Uq7\nurZ7vGhi0UjLRq12EH5Q/LAR1BWYBA69XeLMurHGJR6r86KUnRY/18Yml5TO3H0XHbvvn74puf25\np/nxelt8rvojLimNxlyObJIehVuBLDcmrzMAmPN53Olx52FRpOfYKj739TqXFUeR8zDox1cGffeY\nAXUYuAsRnGtedOcXIlOU/EJkipJfiExR8guRKUp+ITJlweV0DROy6tns8DpsrW56ZbNd5+9day/x\nlWhEJcQDL0WNLNgOh7w+22CLG2raZZeOjUldNwDY2eHP7dhSeum41eamGdvkBqnxgM9VUeNj3WPp\neofXLnNjz7ElbpDa3eExjoZBLcdm+nlv7fA4Ol3edmscrLJXgVLkQaY1LD043o6uYXIuUu8yhe78\nQmSKkl+ITFHyC5EpSn4hMkXJL0SmKPmFyJR52nXdA+DPAJzGtHDYBXf/rJmdAPAVAPdi2rLr/e7O\nHS4AYECNGF12t7lcUxL9rVnjBoxui8toxTAoWhcU8Svqaa1vucMlqqhtWLMM2nytnqBjnRaXonr9\nfnL7To9LZbVgHmvcx4JOh8uHd506lty+foMbjDxoX2Yll9iGE/56uqdfz9L462zgT7qKTD9FIAMW\n/HxO5MOyFhyPtJVjre1SzHPnHwP4Y3d/G4B3AvhDM3sbgEcAPOHu9wF4Yva7EOINwp7J7+6X3f27\ns5+3ADwP4CyAhwA8NnvYYwDee1hBCiHuPPv6zG9m9wJ4O4CnAJx298uzoZcx/VgghHiDMHfym9kS\ngK8B+Ki7v+Y7qz79oJH8sGFm583sopldHPYHBwpWCHHnmCv5zayOaeJ/0d2/Ptt8xczOzMbPAEg2\neXf3C+5+zt3PNYJmE0KIxbJn8puZAfgCgOfd/dM3DT0O4OHZzw8D+OadD08IcVjM4+r7dQAfAvB9\nM3tmtu1jAD4J4Ktm9mEAPwXw/r0OZO4ox2kpqhU4osabaVmjP+LOt/GIyz/toDeYB22QmFjTaHDJ\na2UlXbMQABDITcdXuXzYCOLvbaVbgFXO56NW48er1bn8Ngnq4G1upOWyImiFderuUzyOGp/jl278\nDR2rN9L9y8o2l+yGFrgVV9Lt5gCgG7gBhyNeZ7C3lR5rBn8p93uBXD0neya/u/8VeLXA3zpwBEKI\nI0Hf8BMiU5T8QmSKkl+ITFHyC5EpSn4hMmWxBTyrCXw3XZSwGHEnlRPX1s4u/8ZgGchv7RYvFjoJ\nJLHNQdoZVwvaf1UVP1414VLljaDw52ogAxaWFmZOnDhO9xkOubw55GFgu88lsc0y/dq0O1wOW99c\np2OTwK1WBsVJCyLpDQIHYUSt4vv5OHAlGo9/aSl9Pa5dT8visyMGY/OhO78QmaLkFyJTlPxCZIqS\nX4hMUfILkSlKfiEyZbFSnzswTktA9aD4YbeTlqkmgdoxcC6j9XZ5Mcuo4Ga3my4KWpSkiR9il2C7\nETjcVric12rz/W7cSNdQLYMCmFEhzjcHrsS/feGndKzVSbvpRgPef253yF+XSVSXMiqcSSS2oHYq\nKgvkWVIQdK9jRsocu36aLX4t7myn5+pOF/AUQvwcouQXIlOU/EJkipJfiExR8guRKQtd7Xd3jEZp\n80N3hZttRqO0QlAVfJV9EJhm2sb3m0z4au6E1AUcTLgpaaXD24YdC1bSm8FzczKHADAmbZyaTa4Q\ntFrplXkA2CJzDwCjiq/OWyMd40pg7Bn2+Ll6m1wlWFnmx6y30kpG2Yzaf/FrZ3s7XSMRAM7e/Qt8\nvx43LQ1Ji7WoNuSdQHd+ITJFyS9Epij5hcgUJb8QmaLkFyJTlPxCZMqeUp+Z3QPgzzBtwe0ALrj7\nZ83sEwB+H8C12UM/5u7f2uNgQC1tVqgKbkgYV2kpzcGND7XAbNMIWj8NgxZgrNbdcMKlt3rQhqx2\nfJWOTQI5r6zx59ZspmU7K7gc2V3iUt/69S06ds+9vL1WUabnqhuYiBDUT+xf5e2ullaO0bEmmaui\nxl+XVpPP77jJr49Gkz+3VsXneNBPz3EkO7MWa0ZqOCaPMcdjxgD+2N2/a2bLAJ42s2/Pxj7j7v9x\n7rMJIV43zNOr7zKAy7Oft8zseQBnDzswIcThsq/P/GZ2L4C3A3hqtukjZvasmT1qZrw2tBDidcfc\nyW9mSwC+BuCj7r4J4HMA3grgfkz/MvgU2e+8mV00s4vDIf/cKYRYLHMlv5nVMU38L7r71wHA3a+4\n+8TdKwCfB/BAal93v+Du59z9XCOokiOEWCx7Jr9Nlw+/AOB5d//0TdvP3PSw9wF47s6HJ4Q4LOZZ\n7f91AB8C8H0ze2a27WMAPmhm92Mq/70A4A/2OpADGBI1pyi5q6/ZTP/FMBxw2aUVuNja7cDFdp27\nx6yeloBaUQ25Pne+jUk9QwAo6/x9eTTkbZxWW2mH21pQH28ncOct371Ex+oDLm2xrlaDIZfsvODS\n1l13n6Bjo+A6QJWWHEdBq7d6i7+eZjzGep3/ZTtY4zImfP/m2rKWfl77UPrmWu3/K6TLD8aavhDi\ndY2+4SdEpij5hcgUJb8QmaLkFyJTlPxCZMpCC3hW7hgQDaiocfmthvQ+kcRjQdui0Zg75hotLhGy\ntlCNoBdTO/hiUxn0d/JA6tve4E67+iQtKVXOn/M/vPwKHTv+ppN0bNjnstdgJy3pWS0okBr05KoF\nTkar+FyNyWs9HPNrxwPpdjDgUuXuLpeJI5cpK7pab/CcqHwnuT1qD3cruvMLkSlKfiEyRckvRKYo\n+YXIFCW/EJmi5BciUxYq9RVFgVYn7d7b7KWlC4C75hrkWABgFhUE5Q6rJnHFAcBglC5GUgWyYrPL\ne/UFPq+wb11U2LGydIyjQNpaWeaFRH3ML5FBULh0gHSMx9v8NVsNXs/tDX59bAT9BIfD9NgwkHub\nXR7HiePcXdgnPfeAaZ9KBotxRHpDAlw63IepT3d+IXJFyS9Epij5hcgUJb8QmaLkFyJTlPxCZMpC\npT4zQ530GIu8SBOiX/QCiafT4MUlu8vLdGx3yCUg5h6bkF6CANAb8LF60Nst6tUX9WNrdtOuxPqY\nx1F54Jib8Euk199/3zonBTUBoNXiDsidQN4sSV/A6Vh6riYDLqNFElu3zV2fvW1eCNUD52FFnK6j\nUfCcCxLHPip46s4vRKYo+YXIFCW/EJmi5BciU5T8QmTKnqv9ZtYC8CSA5uzxf+7uHzeztwD4MoC7\nADwN4EPuHvRNmpoOap5ejawF9eyMWGCiemVW48cLSsXBjU8JMyU5+NPuBzXfsMXNKoiMOB2+4rxF\nDEEVmXcA6PeD1lXBJeKBQapikxzUJmT19gBgzPp/ATh5ipttuoO0kjF48Qrdp+KL7GGMw6AlWr3G\nzUKdbrpWH13RB7C+xl+zeZnnzj8A8Jvu/muYtuN+0MzeCeBPAHzG3X8JwBqADx84GiHEwtgz+X3K\nq2VJ67N/DuA3Afz5bPtjAN57KBEKIQ6FuT7zm1k569B7FcC3Afw9gHX3f6wH/SKAs4cTohDiMJgr\n+d194u73A3gzgAcA/PK8JzCz82Z20cwuDoNvuwkhFsu+VvvdfR3AXwL45wBWzf5xdezNAC6RfS64\n+zl3P9do8q9vCiEWy57Jb2anzGx19nMbwG8DeB7TN4Hfmz3sYQDfPKwghRB3nnmMPWcAPGZmJaZv\nFl919/9uZj8E8GUz+/cA/gbAF/Y6UAFDh0lpgfxmpIaf17kxpgpq+EX12yYVn5KiSMtGbtwYUzS4\nXFOv83OVJR+rSEsuAFhfT9eRK+o8xnYrqIUY3B4a0WtGpD4LqswNAo3NGnw+2oHZ5vraRnJ7p81r\nKzYDKXUy4dJt1FIMFlVsZGN8n/3U6mPsmfzu/iyAtye2/wTTz/9CiDcg+oafEJmi5BciU5T8QmSK\nkl+ITFHyC5EpFrURuuMnM7sG4KezX08CeGVhJ+cojteiOF7LGy2Of+Lup+Y54EKT/zUnNrvo7ueO\n5OSKQ3EoDv3ZL0SuKPmFyJSjTP4LR3jum1Ecr0VxvJaf2ziO7DO/EOJo0Z/9QmTKkSS/mT1oZv/b\nzH5sZo8cRQyzOF4ws++b2TNmdnGB533UzK6a2XM3bTthZt82sx/N/j9+RHF8wswuzebkGTN7zwLi\nuMfM/tLMfmhmPzCzP5ptX+icBHEsdE7MrGVmf21m35vF8e9m299iZk/N8uYrZsZtrfPg7gv9B6DE\ntAzYLwJoAPgegLctOo5ZLC8AOHkE5/0NAO8A8NxN2/4DgEdmPz8C4E+OKI5PAPjXC56PMwDeMft5\nGcDfAXjbouckiGOhc4KpY3dp9nMdwFMA3gngqwA+MNv+nwD8q4Oc5yju/A8A+LG7/8Snpb6/DOCh\nI4jjyHD3JwHcuGXzQ5gWQgUWVBCVxLFw3P2yu3939vMWpsVizmLBcxLEsVB8yqEXzT2K5D8L4Gc3\n/X6UxT8dwF+Y2dNmdv6IYniV0+5+efbzywBOH2EsHzGzZ2cfCw7948fNmNm9mNaPeApHOCe3xAEs\neE4WUTQ39wW/d7n7OwD8SwB/aGa/cdQBAdN3fsRdyw+TzwF4K6Y9Gi4D+NSiTmxmSwC+BuCj7r55\n89gi5yQRx8LnxA9QNHdejiL5LwG456bfafHPw8bdL83+vwrgGzjaykRXzOwMAMz+v3oUQbj7ldmF\nVwH4PBY0J2ZWxzThvujuX59tXvicpOI4qjmZnXvfRXPn5SiS/zsA7putXDYAfADA44sOwsy6Zrb8\n6s8AfgfAc/Feh8rjmBZCBY6wIOqryTbjfVjAnJiZYVoD8nl3//RNQwudExbHoudkYUVzF7WCectq\n5nswXUn9ewD/5ohi+EVMlYbvAfjBIuMA8CVM/3wcYfrZ7cOY9jx8AsCPAPwvACeOKI7/AuD7AJ7F\nNPnOLCCOd2H6J/2zAJ6Z/XvPouckiGOhcwLgn2FaFPdZTN9o/u1N1+xfA/gxgP8GoHmQ8+gbfkJk\nSu4LfkJki5JfiExR8guRKUp+ITJFyS9Epij5hcgUJb8QmaLkFyJT/i+HmTDK4oRmrgAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hz-Zx5SIy4HE",
        "colab": {}
      },
      "source": [
        "# conver the pixel values in float\n",
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')\n",
        "# scale the images\n",
        "xtrain /= 255  # ths is eqvalent to xtrain = xtrain/255 \n",
        "xtest /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rZhGxFxNy4Hm",
        "outputId": "fbb18662-f118-44c6-f9c1-bf4c76406789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2GMDhNpPNv",
        "colab_type": "code",
        "outputId": "44f8566a-6fc8-4962-a2cf-0607fedf1056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "print(xtrain[10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.20784314 0.25490198 0.20784314]\n",
            "  [0.21176471 0.24705882 0.20392157]\n",
            "  [0.21960784 0.23529412 0.19607843]\n",
            "  ...\n",
            "  [0.18431373 0.2        0.19607843]\n",
            "  [0.16078432 0.1764706  0.17254902]\n",
            "  [0.09411765 0.10980392 0.10588235]]\n",
            "\n",
            " [[0.18039216 0.23137255 0.16078432]\n",
            "  [0.20784314 0.24313726 0.1764706 ]\n",
            "  [0.21176471 0.23137255 0.17254902]\n",
            "  ...\n",
            "  [0.16470589 0.18039216 0.1764706 ]\n",
            "  [0.15294118 0.16862746 0.16470589]\n",
            "  [0.10980392 0.1254902  0.12156863]]\n",
            "\n",
            " [[0.1764706  0.23137255 0.14901961]\n",
            "  [0.19607843 0.23529412 0.16078432]\n",
            "  [0.18039216 0.20392157 0.13333334]\n",
            "  ...\n",
            "  [0.14901961 0.16470589 0.16078432]\n",
            "  [0.14117648 0.15686275 0.15294118]\n",
            "  [0.11372549 0.12941177 0.1254902 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.2784314  0.3254902  0.25882354]\n",
            "  [0.2901961  0.3254902  0.25882354]\n",
            "  [0.3137255  0.33333334 0.2627451 ]\n",
            "  ...\n",
            "  [0.2        0.21176471 0.12941177]\n",
            "  [0.18039216 0.19215687 0.13333334]\n",
            "  [0.19215687 0.19607843 0.16078432]]\n",
            "\n",
            " [[0.29411766 0.32156864 0.2627451 ]\n",
            "  [0.30980393 0.33333334 0.27058825]\n",
            "  [0.31764707 0.33333334 0.2627451 ]\n",
            "  ...\n",
            "  [0.23921569 0.25490198 0.16078432]\n",
            "  [0.2509804  0.2627451  0.1882353 ]\n",
            "  [0.1882353  0.19607843 0.16078432]]\n",
            "\n",
            " [[0.33333334 0.3254902  0.2784314 ]\n",
            "  [0.33333334 0.32941177 0.2784314 ]\n",
            "  [0.3372549  0.3372549  0.27450982]\n",
            "  ...\n",
            "  [0.23921569 0.25490198 0.15294118]\n",
            "  [0.2509804  0.2627451  0.18039216]\n",
            "  [0.19215687 0.19607843 0.16078432]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0JDs9BdpgzM",
        "colab_type": "code",
        "outputId": "7f6c8ee3-011a-4c68-ffc5-00fcdf8a7491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ytrain[10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i3PGpIU7y4Hz",
        "outputId": "7b59d713-ea25-4a94-cdf8-2a89ba184d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=xtrain.shape[1:]))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(32, (3, 3)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))  # Drops 25% pixels, which are not important.\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())  # it converts a 2D image (eg. 12,12) into a 1D vector (1,144)\n",
        "model.add(layers.Dense(512)) # Adding a hidden layer with 512 neurons, fully connected layer\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10))  # this is the actual output layer\n",
        "model.add(layers.Activation('softmax')) \n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQkjg8bty4Ip",
        "outputId": "c3cad767-8e3d-4ce9-f7c1-2aa808f132f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(xtrain,ytrain,validation_split=0.1,verbose=True,epochs=100,batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 13s 299us/step - loss: 2.1888 - acc: 0.1809 - val_loss: 2.0424 - val_acc: 0.2802\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 2.0119 - acc: 0.2652 - val_loss: 1.9365 - val_acc: 0.3070\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.9028 - acc: 0.3146 - val_loss: 1.8294 - val_acc: 0.3556\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.8280 - acc: 0.3424 - val_loss: 1.7985 - val_acc: 0.3654\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.7748 - acc: 0.3659 - val_loss: 1.7169 - val_acc: 0.3914\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.7323 - acc: 0.3813 - val_loss: 1.6897 - val_acc: 0.4058\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 1.7016 - acc: 0.3914 - val_loss: 1.6620 - val_acc: 0.4128\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.6712 - acc: 0.4013 - val_loss: 1.6156 - val_acc: 0.4220\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 1.6434 - acc: 0.4133 - val_loss: 1.6079 - val_acc: 0.4320\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.6173 - acc: 0.4208 - val_loss: 1.5476 - val_acc: 0.4478\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.6022 - acc: 0.4253 - val_loss: 1.5419 - val_acc: 0.4522\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.5810 - acc: 0.4336 - val_loss: 1.5221 - val_acc: 0.4598\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.5588 - acc: 0.4436 - val_loss: 1.4804 - val_acc: 0.4706\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.5450 - acc: 0.4463 - val_loss: 1.4547 - val_acc: 0.4834\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.5209 - acc: 0.4559 - val_loss: 1.5122 - val_acc: 0.4656\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.5079 - acc: 0.4595 - val_loss: 1.4363 - val_acc: 0.4910\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.4918 - acc: 0.4673 - val_loss: 1.4158 - val_acc: 0.4990\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.4731 - acc: 0.4729 - val_loss: 1.4105 - val_acc: 0.5038\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.4606 - acc: 0.4792 - val_loss: 1.3755 - val_acc: 0.5104\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.4462 - acc: 0.4829 - val_loss: 1.3806 - val_acc: 0.5124\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.4337 - acc: 0.4889 - val_loss: 1.3727 - val_acc: 0.5118\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.4204 - acc: 0.4916 - val_loss: 1.3601 - val_acc: 0.5242\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.4112 - acc: 0.4958 - val_loss: 1.3337 - val_acc: 0.5306\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.3985 - acc: 0.5040 - val_loss: 1.3519 - val_acc: 0.5234\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.3876 - acc: 0.5067 - val_loss: 1.3136 - val_acc: 0.5374\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.3759 - acc: 0.5105 - val_loss: 1.2834 - val_acc: 0.5542\n",
            "Epoch 27/100\n",
            "24000/45000 [===============>..............] - ETA: 2s - loss: 1.3613 - acc: 0.5178"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "03Ie9M5Ky4JS",
        "outputId": "7062592f-d63e-4df2-d582-efb05082c64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# check performance on test\n",
        "scores = model.evaluate(xtest, ytest, verbose=1) \n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 144us/step\n",
            "Test loss: 0.8888397757530212\n",
            "Test accuracy: 0.6919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-qJQmdpjy4Jv",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "072onwh75dkX",
        "colab_type": "text"
      },
      "source": [
        "So the model's final accuracy on the TEST data is 69%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTAD2_t5i_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}